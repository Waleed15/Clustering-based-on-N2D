{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02cea9f-8b88-48fa-8f37-7543353bd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random as rn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import umap\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "from time import time\n",
    "from keras.datasets import mnist\n",
    "import umap.plot\n",
    "\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ca41e5-6397-475a-bfe1-483c3e7f01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b96d10-b8e1-40d7-b51d-2b75993b017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "matplotlib.use('agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ce6e55-c26f-4c0a-a970-26b57e9f21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(dims, act='relu'):\n",
    "    n_stacks = len(dims) - 1\n",
    "    x = Input(shape=(dims[0],), name='input')\n",
    "    h = x\n",
    "    for i in range(n_stacks - 1):\n",
    "        h = Dense(dims[i + 1], activation=act, name='encoder_%d' % i)(h)\n",
    "    h = Dense(dims[-1], name='encoder_%d' % (n_stacks - 1))(h)\n",
    "    for i in range(n_stacks - 1, 0, -1):\n",
    "        h = Dense(dims[i], activation=act, name='decoder_%d' % i)(h)\n",
    "    h = Dense(dims[0], name='decoder_0')(h)\n",
    "\n",
    "    return Model(inputs=x, outputs=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1c9ff9-c731-4124-bbc6-fd6af1759575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(n_clusters=20, batch_size=256, pretrain_epochs=50, ae_weights=None, save_dir='results/n2d', umap_dim=2, umap_neighbors=10, umap_min_dist='0.00', umap_metric='euclidean', cluster='GMM', eval_all=False, manifold_learner='UMAP', visualize=True)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "        description='(Not Too) Deep',\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--n_clusters', default=20, type=int)\n",
    "parser.add_argument('--batch_size', default=256, type=int)\n",
    "parser.add_argument('--pretrain_epochs', default=50, type=int)\n",
    "parser.add_argument('--ae_weights', default=None)\n",
    "parser.add_argument('--save_dir', default='results/n2d')\n",
    "parser.add_argument('--umap_dim', default=2, type=int)\n",
    "parser.add_argument('--umap_neighbors', default=10, type=int)\n",
    "parser.add_argument('--umap_min_dist', default=\"0.00\", type=str)\n",
    "parser.add_argument('--umap_metric', default='euclidean', type=str)\n",
    "parser.add_argument('--cluster', default='GMM', type=str)\n",
    "parser.add_argument('--eval_all', default=False, action='store_true')\n",
    "parser.add_argument('--manifold_learner', default='UMAP', type=str)\n",
    "parser.add_argument('--visualize', default=True, action='store_true')\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9cff5a2-1e6e-492d-9536-8dbd02a7e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe1a8e2-8f8f-4d5c-88d9-8716cc9d2538",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "train_data_dir = os.path.join(path, r'..\\..\\..\\..\\originals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aedbfe5a-0ede-4148-82a2-5d5ea746be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path,size):\n",
    "    count = 0\n",
    "    image_data = []\n",
    "    x_data = []\n",
    "    train_folder_path = path                                                        # Folder Path\n",
    "    for img in os.listdir(train_folder_path):                                       # This will iterate in the Folder\n",
    "        if count < 50000:\n",
    "            new_path = os.path.join(train_folder_path, img)                             # image Path\n",
    "            image_data_temp = cv2.imread(new_path)                 # Read Image as numbers\n",
    "            image_temp_resize = cv2.resize(image_data_temp,(size,size))\n",
    "            image_data.append([image_temp_resize])\n",
    "            #rn.shuffle(image_data)\n",
    "            count = count + 1 \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    data = np.asanyarray(image_data)\n",
    "\n",
    "    # Iterate over the Data\n",
    "    for x in data:\n",
    "        x_data.append(x[0])        # Get the X_Data\n",
    "\n",
    "    X_Data = np.asarray(x_data) / (255.0)      # Normalize Data\n",
    "\n",
    "    # reshape x_Data\n",
    "\n",
    "    X_Data = X_Data.reshape(-1, size, size, 3)\n",
    "\n",
    "    return X_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06feec93-dde8-4abb-ab4e-8b9beabf65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainimages = load_dataset(train_data_dir,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8228d20d-abb3-4559-99d2-007d9d964534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x299ab59f340>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(trainimages[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9cd12b-f453-4867-8227-6de36be1a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trainimages\n",
    "x = x.reshape((x.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a6161c2-4281-415a-8eeb-a4b303c35051",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [x.shape[-1], 500, 500, 2000, args.n_clusters]\n",
    "autoencoder = autoencoder(shape)\n",
    "\n",
    "hidden = autoencoder.get_layer(name='encoder_%d' % (len(shape) - 2)).output\n",
    "encoder = Model(inputs=autoencoder.input, outputs=hidden)\n",
    "\n",
    "pretrain_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5f837-7211-4ace-a034-d20fbe91a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain autoencoders before clustering\n",
    "if args.ae_weights is None:\n",
    "    autoencoder.compile(loss='mse', optimizer=optimizer)\n",
    "    autoencoder.fit(\n",
    "        x,\n",
    "        x,\n",
    "        batch_size=args.batch_size,\n",
    "        epochs=args.pretrain_epochs,\n",
    "        verbose=0)\n",
    "    pretrain_time = time() - pretrain_time\n",
    "    # autoencoder.save_weights('weights/' +\n",
    "    #                          args.dataset +\n",
    "    #                          \"-\" +\n",
    "    #                          str(args.pretrain_epochs) +\n",
    "    #                          '-ae_weights.h5')\n",
    "    print(\"Time to train the autoencoder: \" + str(pretrain_time))\n",
    "else:\n",
    "    autoencoder.load_weights('weights/' + args.ae_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585c2bd-9e5e-4d19-8e36-40c8b67798d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl = encoder.predict(x)\n",
    "# np.savetxt(args.save_dir + \"/\" + args.dataset + '-clusters.txt', clusters, fmt='%i', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ad0e2-413b-4c94-94da-d6b9076eb9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = float(args.umap_min_dist)\n",
    "hle = umap.UMAP(random_state=0,\n",
    "                metric=args.umap_metric,\n",
    "                n_components=args.umap_dim,\n",
    "                n_neighbors=args.umap_neighbors,\n",
    "                min_dist=md).fit(hl)\n",
    "umap.plot.points(hle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752bab74-6d5e-422b-b370-bbcc14a60f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
